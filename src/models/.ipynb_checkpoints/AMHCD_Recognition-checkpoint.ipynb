{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6963415d",
   "metadata": {},
   "source": [
    "# Import the requerment Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1621ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Cell is executed without errors\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #for number array and rgb image pixel values and feautres\n",
    "#to buid a dataframe for confusion matrix\n",
    "import pandas as pd\n",
    "#for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#Allow charts and graphics to display right below the page of browser setup\n",
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "#to use tools needed for deep learning\n",
    "from tensorflow.keras.models import Sequential,load_model,Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam,Adagrad\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import LeakyReLU \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "np.random.seed(2)\n",
    "#to generate random numbers\n",
    "import random \n",
    "#fro models evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "#RandomForest sklearn implementation\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "print('the Cell is executed without errors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233a5548",
   "metadata": {},
   "source": [
    "# Data preprocessingÂ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d536cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ya': 0, 'yab': 1, 'yach': 2, 'yad': 3, 'yadd': 4, 'yae': 5, 'yaf': 6, 'yag': 7, 'yagh': 8, 'yagw': 9, 'yah': 10, 'yahh': 11, 'yaj': 12, 'yak': 13, 'yakw': 14, 'yal': 15, 'yam': 16, 'yan': 17, 'yaq': 18, 'yar': 19, 'yarr': 20, 'yas': 21, 'yass': 22, 'yat': 23, 'yatt': 24, 'yaw': 25, 'yax': 26, 'yay': 27, 'yaz': 28, 'yazz': 29, 'yey': 30, 'yi': 31, 'yu': 32}\n",
      "['ya', 'yab', 'yach', 'yad', 'yadd', 'yae', 'yaf', 'yag', 'yagh', 'yagw', 'yah', 'yahh', 'yaj', 'yak', 'yakw', 'yal', 'yam', 'yan', 'yaq', 'yar', 'yarr', 'yas', 'yass', 'yat', 'yatt', 'yaw', 'yax', 'yay', 'yaz', 'yazz', 'yey', 'yi', 'yu']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n"
     ]
    }
   ],
   "source": [
    "data_path=r\"C:\\Users\\kabir\\Projects\\Projects_Acadimic\\Amazigh_handwritten_character_recognition\\data\\raw\\AMHCD_64\"\n",
    "categories=os.listdir(data_path)\n",
    "labels=[i for i in range(len(categories))]\n",
    "label_dict=dict(zip(categories,labels)) #empty dictionary\n",
    "print(label_dict)\n",
    "print(categories)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d06b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=64\n",
    "data=[]\n",
    "target=[]\n",
    "for category in categories:\n",
    "    folder_path=os.path.join(data_path,category)\n",
    "    img_names=os.listdir(folder_path)\n",
    "        \n",
    "    for img_name in img_names:\n",
    "        img_path=os.path.join(folder_path,img_name)\n",
    "        img=cv2.imread(img_path)\n",
    "        try:\n",
    "            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV) \n",
    "            #Coverting the image into gray scale\n",
    "            resized=cv2.resize(thresh ,(img_size,img_size))\n",
    "            #resizing the gray scale into 64x64, since we need a fixed common size for all the images in the dataset\n",
    "            data.append(resized)\n",
    "            target.append(label_dict[category])\n",
    "            #appending the image and the label(categorized) into the list (dataset)\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Exception:',e)\n",
    "            #if any exception rasied, the exception will be printed here. And pass to the next image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
